p + geom_bar(position = "dodge", stat = "identity") + theme(legend.position = "top")
# import data
titanic <- read_csv("input/titanic.csv")
lincoln_temps <- lincoln_weather %>%
mutate(
date = ymd(CST),
month_long = Month,
month = fct_recode(
Month,
Jan = "January",
Feb = "February",
Mar = "March",
Apr = "April",
May = "May",
Jun = "June",
Jul = "July",
Aug = "August",
Sep = "September",
Oct = "October",
Nov = "November",
Dec = "December"
),
mean_temp = `Mean Temperature [F]`
) %>%
select(date, month, month_long, mean_temp) %>%
mutate(month = fct_rev(month)) # fct_recode() places levels in reverse order
# import data
US_census <- read_csv("https://wilkelab.org/SDS375/datasets/US_census.csv")
tx_counties <- US_census %>%
filter(state == "Texas") %>%
select(name, pop2010) %>%
extract(name, "county", regex = "(.+) County") %>%
mutate(popratio = pop2010/median(pop2010)) %>%
arrange(desc(popratio)) %>%
mutate(index = 1:n())
styler:::style_selection()
# import data
titanic <- read_csv("input/titanic.csv")
lincoln_temps <- lincoln_weather %>%
mutate(
date = ymd(CST),
month_long = Month,
month = fct_recode(
Month,
Jan = "January",
Feb = "February",
Mar = "March",
Apr = "April",
May = "May",
Jun = "June",
Jul = "July",
Aug = "August",
Sep = "September",
Oct = "October",
Nov = "November",
Dec = "December"
),
mean_temp = `Mean Temperature [F]`
) %>%
select(date, month, month_long, mean_temp) %>%
mutate(month = fct_rev(month)) # fct_recode() places levels in reverse order
# Making histograms and setting the bin width
ggplot(titanic, aes(age)) +
geom_histogram(binwidth = 5)
# Always set the center as well
ggplot(titanic, aes(age)) +
geom_histogram(
binwidth = 5,  # width of the bins
center = 2.5   # center of the bin containing that value
)
# import data
titanic <- read_csv("input/titanic.csv")
# lincoln_temps <- lincoln_weather %>%
#   mutate(
#     date = ymd(CST),
#     month_long = Month,
#     month = fct_recode(
#       Month,
#       Jan = "January",
#       Feb = "February",
#       Mar = "March",
#       Apr = "April",
#       May = "May",
#       Jun = "June",
#       Jul = "July",
#       Aug = "August",
#       Sep = "September",
#       Oct = "October",
#       Nov = "November",
#       Dec = "December"
#     ),
#     mean_temp = `Mean Temperature [F]`
#   ) %>%
#   select(date, month, month_long, mean_temp) %>%
#   mutate(month = fct_rev(month)) # fct_recode() places levels in reverse order
# Making histograms and setting the bin width
ggplot(titanic, aes(age)) +
geom_histogram(binwidth = 5)
# Always set the center as well
ggplot(titanic, aes(age)) +
geom_histogram(
binwidth = 5,  # width of the bins
center = 2.5   # center of the bin containing that value
)
# Making density plots
ggplot(titanic, aes(age)) +
geom_density(fill = "skyblue")
# Modifying bandwidth (bw) and kernel parameters
ggplot(titanic, aes(age)) +
geom_density(
fill = "skyblue",
bw = 0.5,               # a small bandwidth
kernel = "gaussian"     # Gaussian kernel (the default)
)
ggplot(titanic, aes(age)) +
geom_density(
fill = "skyblue",
bw = 2,                 # a moderate bandwidth
kernel = "rectangular"  # rectangular kernel
)
# Statistical transformations (stats) can be set explicitly
ggplot(titanic, aes(age)) +
geom_density(
stat = "density",    # the default for geom_density()
fill = "skyblue"
)
ggplot(titanic, aes(age)) +
geom_area(  # geom_area() does not normally use stat = "density"
stat = "density",
fill = "skyblue"
)
ggplot(titanic, aes(age)) +
geom_line(  # neither does geom_line()
stat = "density"
)
ggplot(titanic, aes(age)) +
# we can use multiple geoms on top of each other
geom_area(stat = "density", fill = "skyblue") +
geom_line(stat = "density")
# Parameters are handed through to the stat
ggplot(titanic, aes(age)) +
geom_line(stat = "density", bw = 3) # bw is a parameter of stat_density(), not of geom_line()
ggplot(titanic, aes(age)) +
geom_line(stat = "density", bw = 0.3)
# We can explicitly map results from stat computations
ggplot(titanic, aes(age)) +
geom_tile( # geom_tile() draws rectangular colored areas
aes(
y = 1, # draw all tiles at the same y location
fill = after_stat(density)  # use computed density for fill
),
stat = "density",
n = 20    # number of points calculated by stat_density()
)
ggplot(titanic, aes(age)) +
geom_tile( # geom_tile() draws rectangular colored areas
aes(
y = 1, # draw all tiles at the same y location
fill = after_stat(density)  # use computed density for fill
),
stat = "density",
n = 200   # number of points calculated by stat_density()
)
# Boxplot
ggplot(lincoln_temps, aes(x = month, y = mean_temp)) +
geom_boxplot(fill = "skyblue")
# Violin plot
ggplot(lincoln_temps, aes(x = month, y = mean_temp)) +
geom_violin(fill = "skyblue")
# Strip chart
ggplot(lincoln_temps, aes(x = month, y = mean_temp)) +
geom_point(size = 0.75)  # reduce point size to minimize overplotting
ggplot(lincoln_temps, aes(x = month, y = mean_temp)) +
geom_point(size = 0.75,  # reduce point size to minimize overplotting
position = position_jitter(
width = 0.15,  # amount of jitter in horizontal direction
height = 0     # amount of jitter in vertical direction (0 = none)
)
)
# Sina plot
ggplot(lincoln_temps, aes(x = month, y = mean_temp)) +
geom_violin(fill = "skyblue", color = NA) + # violins in background
geom_sina(size = 0.75) # sina jittered points in foreground
# Ridgeline plot
ggplot(lincoln_temps, aes(x = mean_temp, y = month_long)) +
geom_density_ridges()
# import data
US_census <- read_csv("https://wilkelab.org/SDS375/datasets/US_census.csv")
tx_counties <- US_census %>%
filter(state == "Texas") %>%
select(name, pop2010) %>%
extract(name, "county", regex = "(.+) County") %>%
mutate(popratio = pop2010/median(pop2010)) %>%
arrange(desc(popratio)) %>%
mutate(index = 1:n())
# import data
US_census <- read_csv("https://wilkelab.org/SDS375/datasets/US_census.csv")
# tx_counties <- US_census %>%
#   filter(state == "Texas") %>%
#   select(name, pop2010) %>%
#   extract(name, "county", regex = "(.+) County") %>%
#   mutate(popratio = pop2010/median(pop2010)) %>%
#   arrange(desc(popratio)) %>%
#   mutate(index = 1:n())
# The parameter name sets the axis title
ggplot(boxoffice) +
aes(amount, fct_reorder(title, amount)) +
geom_col() +
scale_x_continuous(
name = "weekend gross (million USD)" # We could do the same with xlab() and ylab()
) +
scale_y_discrete(
name = NULL  # no axis title
)
# The parameter limits sets the scale limits
ggplot(boxoffice) +
aes(amount, fct_reorder(title, amount)) +
geom_col() +
scale_x_continuous(
name = "weekend gross (million USD)",
limits = c(0, 80) # We could do the same with xlim() and ylim()
) +
scale_y_discrete(
name = NULL
)
# The parameter breaks sets the axis tick positions
ggplot(boxoffice) +
aes(amount, fct_reorder(title, amount)) +
geom_col() +
scale_x_continuous(
name = "weekend gross (million USD)",
limits = c(0, 80),
breaks = c(0, 25, 50, 75)
) +
scale_y_discrete(
name = NULL
)
# The parameter labels sets the axis tick labels
ggplot(boxoffice) +
aes(amount, fct_reorder(title, amount)) +
geom_col() +
scale_x_continuous(
name = "weekend gross",
limits = c(0, 80),
breaks = c(0, 25, 50, 75),
labels = c("0", "$25M", "$50M", "$75M")
) +
scale_y_discrete(
name = NULL
)
# The parameter expand sets the axis expansion
ggplot(boxoffice) +
aes(amount, fct_reorder(title, amount)) +
geom_col() +
scale_x_continuous(
name = "weekend gross (million USD)",
limits = c(0, 80),
breaks = c(0, 25, 50, 75),
labels = c("0", "$25M", "$50M", "$75M"),
expand = expansion(mult = c(0, 0.06))
) +
scale_y_discrete(
name = NULL
)
# Linear y scale
ggplot(tx_counties) +
aes(x = index, y = popratio) +
geom_point() +
scale_y_continuous(
name = "population number / median",
breaks = c(0, 100, 200),
labels = c("0", "100", "200")
)
# Log y scale
ggplot(tx_counties) +
aes(x = index, y = popratio) +
geom_point() +
scale_y_log10(
name = "population number / median",
breaks = c(0.01, 1, 100),
labels = c("0.01", "1", "100")
)
# Coords define the coordinate system
ggplot(temperatures, aes(day_of_year, temperature, color = location)) +
geom_line() +
coord_cartesian()  # cartesian coords are the default
ggplot(temperatures, aes(day_of_year, temperature, color = location)) +
geom_line() +
coord_polar()   # polar coords
ggplot(temperatures, aes(day_of_year, temperature, color = location)) +
geom_line() +
coord_polar() +
scale_y_continuous(limits = c(0, 105))  # fix up temperature limits
## By default, show code for all chunks in the knitted document,
## as well as the output. To override for a particular chunk
## use echo = FALSE in its options.
knitr::opts_chunk$set(
echo=TRUE, message=FALSE, warning=FALSE
)
# CONFIG
user_name <- "fernandomillanvillalobos" # your Git username (only needed if
# you want to deploy to GH pages)
project_name <- "datavizR" # adapt!
package_date <- "2021-06-01" # date of the CRAN snapshot that
# the checkpoint package uses
r_version <- "4.1.1" # R-Version to use
options(Ncpus = 4) # use 4 cores for parallelized installation of packages
if (r_version != paste0(version$major, ".", version$minor)) {
stop("ERROR: specified R version does not match currently used.")
}
detach_all_packages <- function() {
basic_packages_blank <-  c("stats",
"graphics",
"grDevices",
"utils",
"datasets",
"methods",
"base")
basic_packages <- paste("package:", basic_packages_blank, sep = "")
package_list <- search()[
ifelse(unlist(gregexpr("package:", search())) == 1, TRUE, FALSE)]
package_list <- setdiff(package_list, basic_packages)
if (length(package_list) > 0)  for (package in package_list) {
detach(package, character.only = TRUE, unload = TRUE)
print(paste("package ", package, " detached", sep = ""))
}
}
detach_all_packages()
# this allows multiple persons to use the same RMarkdown
# without adjusting the working directory by themselves all the time
source("scripts/csf.R")
path_to_wd <- csf() # if this - for some reason - does not work,
# replace with a hardcoded path, like so: "~/projects/rddj-template/analysis/"
if (is.null(path_to_wd) | !dir.exists(path_to_wd)) {
print("WARNING: No working directory specified for current user")
} else {
setwd(path_to_wd)
}
# suppress scientific notation
options(scipen = 999)
# suppress summarise info
options(dplyr.summarise.inform = FALSE)
# unload global rstudioapi and knitr again to avoid conflicts with checkpoint
# this is only necessary if executed within RStudio
# outside of RStudio, namely in the knit.sh script, this causes RMarkdown
# rendering to fail, thus should not be executed there
if (Sys.getenv("RSTUDIO") == "1") {
detach_all_packages()
}
# from https://mran.revolutionanalytics.com/web/packages/\
# checkpoint/vignettes/using-checkpoint-with-knitr.html
# if you don't need a package, remove it from here (commenting not sufficient)
# tidyverse: see https://blog.rstudio.org/2016/09/15/tidyverse-1-0-0/
cat("
library(rstudioapi)
library(tidyverse, warn.conflicts = FALSE) # ggplot2, dplyr, tidyr, readr, purrr, tibble, magrittr, readxl
library(scales) # scales for ggplot2
library(lintr) # code linting
library(rmarkdown)
library(cowplot) # theme
library(extrafont)
library(ggrepel) # text labels
library(gapminder) #data sets
library(socviz) # book Data Visualization: A Practical...
library(RColorBrewer)
library(ggforce)
library(dichromat) # palettes for color-blind
library(ggridges) # density ridges plots
library(viridis) # colors
library(palmerpenguins)
library(lubridate)
library(ggforce)
library(ggthemes) # set of themes
library(nycflights13) # ds example
library(broom) # cleans model output
library(glue) # for easy text formatting
library(ggiraph) # for interaction
library(hexbin)
library(patchwork)
library(distributional) # for dist_normal()
library(psych)
library(introdataviz)
library(ggalluvial)
library(ggdist)
library(ds4psy) # book Data Science for Psychologists
library(ISLR) # tables dataset
library(Rfast) # useful functions
library(MASS)
library(gganimate)",
file = "manifest.R")
# if checkpoint is not yet installed, install it (for people using this
# system for the first time)
if (!require(checkpoint)) {
if (!require(devtools)) {
install.packages("devtools", repos = "http://cran.us.r-project.org")
require(devtools)
}
devtools::install_github("RevolutionAnalytics/checkpoint",
ref = "v0.3.2", # could be adapted later,
# as of now (beginning of July 2017
# this is the current release on CRAN)
repos = "http://cran.us.r-project.org")
require(checkpoint)
}
# nolint start
if (!dir.exists("~/.checkpoint")) {
dir.create("~/.checkpoint")
}
# nolint end
# install packages for the specified CRAN snapshot date
checkpoint(snapshot_date = package_date,
project = path_to_wd,
verbose = T,
scanForPackages = T,
use.knitr = F,
R.version = r_version)
rm(package_date)
source("manifest.R")
unlink("manifest.R")
sessionInfo()
# if you want to outsource logic to other script files, see README for
# further information
# Load all visualizations functions as separate scripts
knitr::read_chunk("scripts/dviz.supp.R")
source("scripts/dviz.supp.R")
knitr::read_chunk("scripts/themes.R")
source("scripts/themes.R")
knitr::read_chunk("scripts/plot_grid.R")
source("scripts/plot_grid.R")
knitr::read_chunk("scripts/align_legend.R")
source("scripts/align_legend.R")
knitr::read_chunk("scripts/label_log10.R")
source("scripts/label_log10.R")
knitr::read_chunk("scripts/outliers.R")
source("scripts/outliers.R")
p <- ggplot(data = gapminder,
mapping = aes(x = year,
y = gdpPercap))
p + geom_line(aes(group=country))
p <- ggplot(data = gapminder,
mapping = aes(x = year,
y = gdpPercap))
p + geom_line(aes(group = country)) + facet_wrap(~ continent)
p <- ggplot(data = gapminder, mapping = aes(x = year, y = gdpPercap))
p + geom_line(color="gray70", aes(group = country)) +
geom_smooth(size = 1.1, method = "loess", se = FALSE) +
scale_y_log10(labels=scales::dollar) +
facet_wrap(~ continent, ncol = 5) +
labs(x = "Year",
y = "GDP per capita",
title = "GDP per capita on Five Continents")
p <- ggplot(data = gss_sm,
mapping = aes(x = age, y = childs))
p + geom_point(alpha = 0.2) +
geom_smooth() +
facet_grid(sex ~ race)
p <- ggplot(data = gss_sm, mapping = aes(x = bigregion))
p + geom_bar() # geom_bar called the default stat_ function associated with it, stat_count().
# We no longer have a count on the y-axis, but the proportions of the bars all have a value of 1, so all the bars are the same height. We want them to sum to 1, so that we get the number of observations per continent as a proportion of the total number of observations. This is a grouping issue again. In a sense, it’s the reverse of the earlier grouping problem we faced when we needed to tell ggplot that our yearly data was grouped by country.
p <- ggplot(data = gss_sm,
mapping = aes(x = bigregion))
p + geom_bar(mapping = aes(y = ..prop..))
# In this case, we need to tell ggplot to ignore the x-categories when calculating denominator of the proportion, and use the total number observations instead. To do so we specify group = 1 inside the aes() call. The value of 1 is just a kind of “dummy group” that tells ggplot to use the whole dataset when establishing the denominator for its prop calculations.
p <- ggplot(data = gss_sm,
mapping = aes(x = bigregion))
p + geom_bar(mapping = aes(y = ..prop.., group = 1)) # 1 is a dummy group
# Another example
p <- ggplot(data = gss_sm,
mapping = aes(x = religion, fill = religion))
p + geom_bar() + guides(fill = FALSE) #  If we set guides(fill = FALSE), the legend is removed
p <- ggplot(data = gss_sm,
mapping = aes(x = bigregion, fill = religion))
p + geom_bar() # The default output of geom_bar() is a stacked bar chart
# An alternative choice is to set the position argument to "fill".
p <- ggplot(data = gss_sm,
mapping = aes(x = bigregion, fill = religion))
p + geom_bar(position = "fill") # the bars are all the same height
# When we just wanted the overall proportions for one variable, we mapped group = 1 to tell ggplot to calculate the proportions with respect to the overall N.
p <- ggplot(data = gss_sm,
mapping = aes(x = bigregion, fill = religion))
p + geom_bar(position = "dodge",
mapping = aes(y = ..prop.., group = religion))
# We can ask ggplot to give us a proportional bar chart of religious affiliation, and then facet that by region
p <- ggplot(data = gss_sm,
mapping = aes(x = religion))
p + geom_bar(position = "dodge",
mapping = aes(y = ..prop.., group = bigregion)) +
facet_wrap(~ bigregion, ncol = 1)
# By default, the geom_histogram() function will choose a bin size for us based on a rule of thumb.
p <- ggplot(data = midwest,
mapping = aes(x = area))
p + geom_histogram()
# selecting another bin size
p <- ggplot(data = midwest,
mapping = aes(x = area))
p + geom_histogram(bins = 10)
oh_wi <- c("OH", "WI")
# subset the data
p <- ggplot(data = subset(midwest, subset = state %in% oh_wi), # %in% operator is a convenient way to filter on more than one termin a variable
mapping = aes(x = percollege, fill = state))
p + geom_histogram(alpha = 0.4, bins = 20)
# When working with a continuous variable, an alternative to binning the data and making a histogram is to calculate a kernel density estimate of the underlying distribution.
p <- ggplot(data = midwest,
mapping = aes(x = area, fill = state, color = state))
p + geom_density(alpha = 0.3)
# For geom_density(), the stat_density() function can return its default ..density.. statistic, or ..scaled.., which will give a proportional density estimate. It can also return a statistic called ..count.., which is the density times the number of points. This can be used in stacked density plots.
p <- ggplot(data = subset(midwest, subset = state %in% oh_wi),
mapping = aes(x = area, fill = state, color = state))
p + geom_density(alpha = 0.3, mapping = (aes(y = ..scaled..)))
p <- ggplot(data = titanic,
mapping = aes(x = fate, y = percent, fill = sex))
p + geom_bar(position = "dodge", stat = "identity") + theme(legend.position = "top")
